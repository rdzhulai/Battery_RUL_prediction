{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdzhulai/Battery_RUL_prediction/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q PyAV torchmetrics"
      ],
      "metadata": {
        "id": "KeDk7QQkzvVw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UkmPXbSrrG1",
        "outputId": "a169584e-3360-473e-c7fe-2a6e85fec3e0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "h4uJkdwLrl-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a346223-26a0-44da-a822-297524c2255b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.2.1+cu121 0.17.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "from torchvision.io import read_image, ImageReadMode\n",
        "from torchvision.models import inception_v3, Inception_V3_Weights\n",
        "from torchvision.models.optical_flow import raft_large, Raft_Large_Weights, Raft_Small_Weights, raft_small\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import torchmetrics\n",
        "\n",
        "print(torch.__version__, torchvision.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyFpu1ES1FOo",
        "outputId": "c5d336c3-137f-4616-8f31-db4de4e9959e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "e-AZY_qBrl-p"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1\n",
        "EPOCHS = 1\n",
        "\n",
        "FRAME_WIDTH = 288\n",
        "FRAME_HEIGHT = 296\n",
        "\n",
        "MAX_SEQ_LENGTH = 5\n",
        "TEMPORAL_STEP = 10\n",
        "\n",
        "DATA_DIR_PATH = \"/content/drive/MyDrive/sliding-classifier/train_data\"\n",
        "SLIDING_METAFILE_PATH = \"/content/drive/MyDrive/sliding-classifier/sliding_metafile.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(SLIDING_METAFILE_PATH)\n",
        "print(f\"{len(df[df['video_class'] == 'ls_p'])} vs {len(df[df['video_class'] == 'ls_a'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQP9CMM-_gDF",
        "outputId": "a2b2cf77-60ab-493c-a1ec-08957c91ab19"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139 vs 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "pSH9fbllrl-q",
        "outputId": "6a3a1ace-7c4d-42b8-815c-73d6899f438f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total videos for training: 102\n",
            "Total videos for testing: 35\n",
            "Total videos for validation: 35\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            video_name video_class\n",
              "100  Sonoscape_2021-09_2021-10-18_002_20211008_1108...        ls_a\n",
              "134                          003_image_70959392795.mp4        ls_p\n",
              "63                               Old_dataset_LSP_2.avi        ls_p\n",
              "27   Sonoscape_2021-09_2021-10-18_002_20210930_1547...        ls_p\n",
              "115                             Old_dataset_LSP_17.avi        ls_p"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc737011-d7cd-4a5e-8b94-4460cde99a78\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "      <th>video_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>Sonoscape_2021-09_2021-10-18_002_20211008_1108...</td>\n",
              "      <td>ls_a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>003_image_70959392795.mp4</td>\n",
              "      <td>ls_p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Old_dataset_LSP_2.avi</td>\n",
              "      <td>ls_p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Sonoscape_2021-09_2021-10-18_002_20210930_1547...</td>\n",
              "      <td>ls_p</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Old_dataset_LSP_17.avi</td>\n",
              "      <td>ls_p</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc737011-d7cd-4a5e-8b94-4460cde99a78')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc737011-d7cd-4a5e-8b94-4460cde99a78 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc737011-d7cd-4a5e-8b94-4460cde99a78');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4fb5235-1628-402c-ac70-0718ecc4c4a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4fb5235-1628-402c-ac70-0718ecc4c4a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4fb5235-1628-402c-ac70-0718ecc4c4a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 102,\n  \"fields\": [\n    {\n      \"column\": \"video_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"Old_dataset_LSP_20.avi\",\n          \"x220819--071841_20220819_MSK_0003s.AVI\",\n          \"021_image_182041262860754.mp4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ls_p\",\n          \"ls_a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Split data into train and test sets (e.g., 80%/20%)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split the train set into train and validation sets (e.g., 60%/20%)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "print(f\"Total videos for training: {len(train_df)}\")\n",
        "print(f\"Total videos for testing: {len(test_df)}\")\n",
        "print(f\"Total videos for validation: {len(test_df)}\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df = train_df.sample(20, random_state=42)\n",
        "# test_df = test_df.sample(5, random_state=42)\n",
        "# val_df = val_df.sample(5, random_state=42)"
      ],
      "metadata": {
        "id": "X8pbOQvNYbhT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# def video_exists(video_name, folder_path):\n",
        "#   \"\"\"\n",
        "#   Checks if a video exists in the specified folder.\n",
        "#   \"\"\"\n",
        "#   file_path = os.path.join(folder_path, video_name)\n",
        "#   return os.path.isfile(file_path)\n",
        "\n",
        "# def filter_dataframe(df, folder_path):\n",
        "#   \"\"\"\n",
        "#   Filters the DataFrame to keep rows where videos exist in the folder.\n",
        "#   \"\"\"\n",
        "#   return df[df[\"video_name\"].apply(lambda name: video_exists(name, folder_path))]\n",
        "\n",
        "# # Filter the DataFrame\n",
        "# train_df = filter_dataframe(train_df, DATA_DIR_PATH)  # Copy to avoid modifying original DataFrame\n",
        "# test_df = filter_dataframe(test_df, DATA_DIR_PATH)\n",
        "\n",
        "# print(f\"Total videos for training: {len(train_df)}\")\n",
        "# print(f\"Total videos for testing: {len(test_df)}\")\n",
        "\n",
        "# train_df.sample(10)"
      ],
      "metadata": {
        "id": "hozkJ2vHtR-I"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-JkQIn9rl-t",
        "outputId": "1ed4ec0c-7d97-49e1-bcc4-1676d4b8c995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ls_a', 'ls_p']\n"
          ]
        }
      ],
      "source": [
        "class VocabularyMapping:\n",
        "    def __init__(self, labels):\n",
        "        self.mapping = {label: index for index, label in enumerate(labels)}\n",
        "\n",
        "    def __call__(self, labels):\n",
        "        return torch.tensor([self.mapping[label] for label in labels], dtype=torch.float32)\n",
        "\n",
        "label_processor = VocabularyMapping(np.unique(train_df[\"video_class\"]))\n",
        "print(list(label_processor.mapping.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OpticalFlowExtractor:\n",
        "  def __init__(self):\n",
        "    weights = Raft_Small_Weights.DEFAULT\n",
        "    self.model = raft_small(weights=weights, progress=False).to(device)\n",
        "    self.model = self.model.eval()\n",
        "    self.transforms = weights.transforms()\n",
        "\n",
        "  def _preprocess(self, frame1_batch, frame2_batch):\n",
        "    frame1_batch = T.functional.resize(frame1_batch, size=[FRAME_HEIGHT, FRAME_WIDTH], antialias=False)\n",
        "    frame2_batch = T.functional.resize(frame2_batch, size=[FRAME_HEIGHT, FRAME_WIDTH], antialias=False)\n",
        "    return self.transforms(frame1_batch, frame2_batch)\n",
        "\n",
        "  def __call__(self, frame1_batch, frame2_batch):\n",
        "    frame1_batch, frame2_batch = self._preprocess(frame1_batch, frame2_batch)\n",
        "    return self.model(frame1_batch, frame2_batch)\n",
        "\n",
        "optical_flow_extractor = OpticalFlowExtractor()"
      ],
      "metadata": {
        "id": "aDEbW3Ssm0G4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NluB9jezrl-t"
      },
      "outputs": [],
      "source": [
        "# class FeatureExtractor:\n",
        "#     def __init__(self):\n",
        "#         weights = Inception_V3_Weights.DEFAULT\n",
        "#         self.model = inception_v3(weights=weights)\n",
        "#         self.model = self.model.eval()\n",
        "#         self.transforms = weights.transforms()\n",
        "\n",
        "#     def preprocess(self, img_batch):\n",
        "#         return self.transforms(img_batch)\n",
        "\n",
        "#     def extract(self, batch):\n",
        "#         return  self.model(batch)\n",
        "\n",
        "# feature_extractor = FeatureExtractor()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.utils import flow_to_image\n",
        "\n",
        "# flow_frames = flow_to_image(flows)\n",
        "# # Assuming your image data is in two lists: list1 (5 elements) and list2 (5 elements)\n",
        "# fig, axes = plt.subplots(5, 2, figsize=(8, 12))  # Adjust figsize for desired size\n",
        "\n",
        "# # Flatten the lists into a single iterator\n",
        "# frame1_batch = [(frame1 + 1) / 2 for frame1 in frame1_batch]\n",
        "\n",
        "# grid = [[frame1.permute(1, 2, 0), flow_frame.permute(1, 2, 0)] for (frame1, flow_frame) in zip(frame1_batch, flow_frames)]\n",
        "# # Enumerate the iterator to get index and image data\n",
        "# for i, (img1, img2) in enumerate(grid):\n",
        "#   # Access subplots based on index (avoiding nested loops)\n",
        "#   #ax1, ax2 = axes[i, 0], axes[i, 1]  # Integer division and modulo for grid position\n",
        "\n",
        "#   axes[i, 0].imshow(img1)\n",
        "#   axes[i, 1].imshow(img2)\n",
        "\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "zHWIAQ_i0bIY"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ck3TSUoXrl-u"
      },
      "outputs": [],
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(size=(FRAME_HEIGHT, FRAME_WIDTH))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# video_path = os.path.join(DATA_DIR_PATH, train_df[\"video_name\"].iloc[4])\n",
        "# frame_names = os.listdir(video_path)\n",
        "# frame_names.sort(key=lambda x: int(x[6:-4]))\n",
        "# frame = read_image(os.path.join(video_path, frame_names[0]), ImageReadMode.RGB).to(device)\n",
        "# transformed = transforms(frame)\n",
        "\n",
        "# plt.imshow(transformed.permute(1, 2, 0).cpu())\n"
      ],
      "metadata": {
        "id": "7MpLlRRlv_4I"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pVQMojo7rl-u"
      },
      "outputs": [],
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, df, root_dir=DATA_DIR_PATH, max_frames=MAX_SEQ_LENGTH):\n",
        "        self.df = df\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "        self.max_frames = max_frames\n",
        "        self.label_processor = label_processor\n",
        "        self.labels = self.label_processor(df[\"video_class\"].values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        video_path = os.path.join(self.root_dir, self.df[\"video_name\"].iloc[idx])\n",
        "        frame_names = os.listdir(video_path)\n",
        "        frame_names.sort(key=lambda x: int(x[6:-4]))\n",
        "\n",
        "        frame1_names_batch = frame_names[:-TEMPORAL_STEP][:MAX_SEQ_LENGTH]\n",
        "        frame2_names_batch = frame_names[TEMPORAL_STEP:][:MAX_SEQ_LENGTH]\n",
        "\n",
        "        frame1_batch = [read_image(os.path.join(video_path, frame_name), ImageReadMode.RGB).to(device) for frame_name in frame1_names_batch]\n",
        "        frame2_batch = [read_image(os.path.join(video_path, frame_name), ImageReadMode.RGB).to(device) for frame_name in frame2_names_batch]\n",
        "\n",
        "        frame1_batch = [self.transforms(frame) for frame in frame1_batch]\n",
        "        frame2_batch = [self.transforms(frame) for frame in frame2_batch]\n",
        "\n",
        "        frame1_batch = torch.stack(frame1_batch).to(device)\n",
        "        frame2_batch = torch.stack(frame2_batch).to(device)\n",
        "\n",
        "        flows = optical_flow_extractor(frame1_batch, frame2_batch)[-1]\n",
        "\n",
        "        return flows, self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr5NhO7Xrl-v",
        "outputId": "163fd4ad-c26a-4b4b-c897-a10fdaaf333c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of items in train dataset: 102\n",
            "Number of items in test dataset: 35\n",
            "Number of items in validation dataset: 34\n"
          ]
        }
      ],
      "source": [
        "train_dataset = VideoDataset(train_df)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset = VideoDataset(test_df)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "val_dataset = VideoDataset(val_df)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "# train_data = next(iter(train_dataloader))\n",
        "print(f\"Number of items in train dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of items in test dataset: {len(test_dataset)}\")\n",
        "print(f\"Number of items in validation dataset: {len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a = next(iter(train_dataloader))\n",
        "# a[0].shape"
      ],
      "metadata": {
        "id": "Y_iQ8ZLY2mPL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ywEPHmRqrl-v"
      },
      "outputs": [],
      "source": [
        "# def prepare_all_videos(df, root_dir):\n",
        "#     num_samples = len(df)\n",
        "#     video_paths = df[\"video_name\"].values.tolist()\n",
        "#     labels = df[\"tag\"].values\n",
        "#     label_tensor = label_processor(labels)\n",
        "\n",
        "#     frame_masks = torch.zeros(num_samples, MAX_SEQ_LENGTH, dtype=torch.bool)\n",
        "#     frame_features = torch.zeros(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES, dtype=torch.float32)\n",
        "\n",
        "#     feature_extractor = FeatureExtractor()\n",
        "\n",
        "#     for idx, path in enumerate(video_paths):\n",
        "#         frames = load_video(os.path.join(root_dir, path), max_frames=MAX_SEQ_LENGTH)\n",
        "#         frames.unsqueeze(0)\n",
        "#         temp_frame_mask = torch.zeros(1, MAX_SEQ_LENGTH, dtype=torch.bool)\n",
        "#         temp_frame_features = torch.zeros(1, MAX_SEQ_LENGTH, NUM_FEATURES, dtype=torch.float32)\n",
        "#         print(frames.shape)\n",
        "#         for i, batch in enumerate(frames):\n",
        "#             video_length = batch.shape[0]\n",
        "#             length = min(MAX_SEQ_LENGTH, video_length)\n",
        "#             # for j in range(length):\n",
        "#             print(batch.unsqueeze(0).shape)\n",
        "#             temp_frame_features[i, :, :] = feature_extractor.extract(batch)\n",
        "#             temp_frame_mask[i, :length] = 1\n",
        "\n",
        "#         frame_features[idx] = temp_frame_features.squeeze()\n",
        "#         frame_masks[idx] = temp_frame_mask.squeeze()\n",
        "\n",
        "#     return (frame_features, frame_masks), label_tensor\n",
        "\n",
        "# train_data, train_labels = prepare_all_videos(train_df, \"data/train\")\n",
        "# test_data, test_labels = prepare_all_videos(test_df, \"data/test\")\n",
        "\n",
        "# print(f\"Frame features in train set: {train_data[0].shape}\")\n",
        "# print(f\"Frame masks in train set: {train_data[1].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Define the convolutional layers\n",
        "# conv1 = torch.nn.Conv3d(in_channels=MAX_SEQ_LENGTH, out_channels=16, kernel_size=(2, 3, 3), stride=1, padding=1)\n",
        "# relu1 = torch.nn.ReLU()\n",
        "# maxpool1 = torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "# conv2 = torch.nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(2, 3, 3), stride=1, padding=1)\n",
        "# relu2 = torch.nn.ReLU()\n",
        "# maxpool2 = torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "# # Define a sample input tensor to get the output size\n",
        "# sample_input = torch.randn((BATCH_SIZE, MAX_SEQ_LENGTH, 2, FRAME_HEIGHT, FRAME_WIDTH))  # Assuming input size is (batch_size, channels, depth, height, width)\n",
        "\n",
        "# # Forward pass to get the output size\n",
        "# x = conv1(sample_input)\n",
        "# x = relu1(x)\n",
        "# x = maxpool1(x)\n",
        "# x = conv2(x)\n",
        "# x = relu2(x)\n",
        "# output = maxpool2(x)\n",
        "\n",
        "# # Print the output size\n",
        "# print(\"Output size:\", output.size())170496\n",
        "\n",
        "# x = torch.nn.Linear(?, 64),  # Adjust input size based on your data shape\n",
        "# torch.nn.ReLU(),\n",
        "#             torch.nn.Linear(64, 2)"
      ],
      "metadata": {
        "id": "CxynlXRU2fGX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "lfFK6xXlrl-w"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Convolution layers\n",
        "        self.conv_layers = torch.nn.Sequential(\n",
        "            torch.nn.Conv3d(in_channels=MAX_SEQ_LENGTH, out_channels=16, kernel_size=(2, 3, 3), stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool3d(kernel_size=2, stride=2),\n",
        "            torch.nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(2, 3, 3), stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc_layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(170496, 64),  # Adjust input size based on your data shape\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.parameters())\n",
        "\n",
        "        # Metrics\n",
        "        self.accuracy = torchmetrics.Accuracy(task='binary')\n",
        "        self.precision = torchmetrics.Precision(task='binary')\n",
        "        self.recall = torchmetrics.Recall(task='binary')\n",
        "        self.f1 = torchmetrics.F1Score(task='binary')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = torch.flatten(x, 1)  # Flatten except batch dimension\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_dataloader, val_dataloader, epochs=EPOCHS):\n",
        "        train_losses = []\n",
        "        val_losses = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            train_loss = 0.0\n",
        "            tqdm_train_loader = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs} - Training\")\n",
        "            for batch_idx, (batch_flows, batch_labels) in enumerate(tqdm_train_loader):\n",
        "                batch_flows, batch_labels = batch_flows.to(device), batch_labels.to(device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self(batch_flows).squeeze(1)\n",
        "                loss = nn.functional.binary_cross_entropy_with_logits(output, batch_labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "                tqdm_train_loader.set_postfix({'train_loss': train_loss / (batch_idx + 1)})\n",
        "\n",
        "            train_losses.append(train_loss)\n",
        "\n",
        "            # Validation phase\n",
        "            val_loss, val_acc, val_precision, val_recall, val_f1 = self.evaluate(val_dataloader)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Validation: Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}, Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}\")\n",
        "\n",
        "        return train_losses, val_losses\n",
        "\n",
        "    def evaluate(self, data_loader):\n",
        "        total_loss = 0.0\n",
        "        self.accuracy.reset()\n",
        "        self.precision.reset()\n",
        "        self.recall.reset()\n",
        "        self.f1.reset()\n",
        "        with torch.no_grad():\n",
        "            tqdm_train_loader = tqdm(data_loader, desc=f\"Epoch 1/1 - Testing\")\n",
        "            for batch_idx, (batch_flows, batch_labels) in enumerate(data_loader):\n",
        "                batch_flows, batch_labels = batch_flows.to(device), batch_labels.to(device)\n",
        "                output = self(batch_flows).squeeze(1)\n",
        "                loss = nn.functional.binary_cross_entropy_with_logits(output, batch_labels)\n",
        "                total_loss += loss.item()\n",
        "                tqdm_train_loader.set_postfix({'loss': loss / (batch_idx + 1)})\n",
        "\n",
        "                predicted = torch.sigmoid(output) > 0.5\n",
        "                self.accuracy(predicted, batch_labels)\n",
        "                self.precision(predicted, batch_labels)\n",
        "                self.recall(predicted, batch_labels)\n",
        "                self.f1(predicted, batch_labels)\n",
        "\n",
        "        return total_loss, self.accuracy.compute(), self.precision.compute(), self.recall.compute(), self.f1.compute()\n",
        "\n",
        "    # def save_weights(self, file_path):\n",
        "    #     torch.save(self.state_dict(), file_path)\n",
        "    #     print(f\"Model weights saved to {file_path}\")\n",
        "\n",
        "\n",
        "    # def load_weights(model, file_path):\n",
        "    #     model.load_state_dict(torch.load(file_path))\n",
        "    #     print(f\"Model weights loaded from {file_path}\")\n",
        "    #     return model\n",
        "\n",
        "    # def save_checkpoint(self, optimizer, epoch, loss, checkpoint_path):\n",
        "    #     checkpoint = {\n",
        "    #         'epoch': epoch,\n",
        "    #         'model_state_dict': self.state_dict(),\n",
        "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
        "    #         'loss': loss\n",
        "    #     }\n",
        "    #     torch.save(checkpoint, checkpoint_path)\n",
        "    #     print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "    # def load_checkpoint(model, optimizer, checkpoint_path):\n",
        "    #     checkpoint = torch.load(checkpoint_path)\n",
        "    #     model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    #     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #     epoch = checkpoint['epoch']\n",
        "    #     loss = checkpoint['loss']\n",
        "    #     print(f\"Checkpoint loaded from {checkpoint_path}, Epoch: {epoch}, Loss: {loss}\")\n",
        "    #     return model, optimizer, epoch, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training phase"
      ],
      "metadata": {
        "id": "ES24vtpcW2kK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "Cz-UZRpJrl-w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657,
          "referenced_widgets": [
            "b45dc7ef01814feeb7dfb4449d8f56b0",
            "a17515ffa8da4a8ba5124b6dbcd0daed",
            "d89f4f8b73f84af49664f0dce79d73d1",
            "c953fdceb7a743d68a755408766732d4",
            "9b6e12c3d2a74360ba1b67880c173947",
            "751ae1cdb380419eadce0409c4efc891",
            "2f8902d362b84041b27fbf15cbe1744f",
            "feb897bab1114d709911ec77b0c4bc55",
            "6d79b6d901cc47bcad16b359792964ea",
            "c171fe8e50304eb3af15f108ecd2718a",
            "e0a6f84b32f445c9930c0fd5f88922e2"
          ]
        },
        "outputId": "2749dc4f-3ec0-45a3-83c8-f3a1c7afb6be"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/1 - Training:   0%|          | 0/102 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b45dc7ef01814feeb7dfb4449d8f56b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "batch_labels size:  torch.Size([1])\n",
            "Epoch 1/1 - Validation: Loss: 17.1901, Accuracy: 0.8235, Precision: 0.8235, Recall: 1.0000, F1: 0.9032\n"
          ]
        }
      ],
      "source": [
        "model = Model().to(device)\n",
        "\n",
        "train_losses, val_losses = model.fit(train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot loss curves"
      ],
      "metadata": {
        "id": "8tNscy0HXFKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U4Esz2RtUGf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "ac9db6bd-f345-42a3-92ee-5174c7694197"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test phase"
      ],
      "metadata": {
        "id": "qxuSSYLZ5TPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase\n",
        "test_loss, test_acc, test_precision, test_recall, test_f1 = model.test(test_dataloader)\n",
        "print(f\"Testing: Loss: {test_loss:.4f}, Accuracy: {test_acc:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "B0jj8CPOVVhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b45dc7ef01814feeb7dfb4449d8f56b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a17515ffa8da4a8ba5124b6dbcd0daed",
              "IPY_MODEL_d89f4f8b73f84af49664f0dce79d73d1",
              "IPY_MODEL_c953fdceb7a743d68a755408766732d4"
            ],
            "layout": "IPY_MODEL_9b6e12c3d2a74360ba1b67880c173947"
          }
        },
        "a17515ffa8da4a8ba5124b6dbcd0daed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_751ae1cdb380419eadce0409c4efc891",
            "placeholder": "​",
            "style": "IPY_MODEL_2f8902d362b84041b27fbf15cbe1744f",
            "value": "Epoch 1/1 - Training: 100%"
          }
        },
        "d89f4f8b73f84af49664f0dce79d73d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feb897bab1114d709911ec77b0c4bc55",
            "max": 102,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6d79b6d901cc47bcad16b359792964ea",
            "value": 102
          }
        },
        "c953fdceb7a743d68a755408766732d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c171fe8e50304eb3af15f108ecd2718a",
            "placeholder": "​",
            "style": "IPY_MODEL_e0a6f84b32f445c9930c0fd5f88922e2",
            "value": " 102/102 [01:41&lt;00:00,  1.25it/s, train_loss=1.57]"
          }
        },
        "9b6e12c3d2a74360ba1b67880c173947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "751ae1cdb380419eadce0409c4efc891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8902d362b84041b27fbf15cbe1744f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feb897bab1114d709911ec77b0c4bc55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d79b6d901cc47bcad16b359792964ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c171fe8e50304eb3af15f108ecd2718a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0a6f84b32f445c9930c0fd5f88922e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}